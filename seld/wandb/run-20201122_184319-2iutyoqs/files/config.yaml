wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.10.10
    code_path: code/seld/main.py
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.7.9
data:
  desc: null
  value:
    audio_feature: logmel&intensity
    feature_freeze: true
    fmax: 12000
    fmin: 20
    hop_length: 600
    n_fft: 1024
    n_mels: 256
    sample_rate: 24000
    test_chunklen_sec: 4
    test_hoplen_sec: 4
    train_chunklen_sec: 4
    train_hoplen_sec: 4
    type: mic
    window: hann
data_augmentation:
  desc: null
  value:
    type: None
dataset:
  desc: null
  value: dcase2020task3
dataset_dir:
  desc: null
  value: /home/alrawis/EIN-SELD/_dataset/dataset_root/
hdf5_dir:
  desc: null
  value: /home/alrawis/EIN-SELD/_hdf5/
inference:
  desc: null
  value:
    batch_size: 64
    infer_id: EINV2_tPIT_n1
    models: EINV2
    overlap: 1&2
    remark: None
    test_fold: None
    testset_type: eval
    threshold_sed: '0.5'
    train_ids: EINV2_tPIT_n1
method:
  desc: null
  value: ein_seld
training:
  desc: null
  value:
    PIT_type: tPIT
    batch_size: 32
    loss_beta: '0.5'
    loss_type: all
    lr: '0.0005'
    lr_gamma: '0.1'
    lr_step_size: 80
    max_epoch: 90
    model: EINV2
    optimizer: adam
    overlap: 1&2
    remark: None
    resume_model: null
    threshold_sed: '0.5'
    train_fold: 2,3,4,5,6
    train_id: EINV2_tPIT_n1
    valid_fold: 1
workspace_dir:
  desc: null
  value: /home/alrawis/EIN-SELD/
